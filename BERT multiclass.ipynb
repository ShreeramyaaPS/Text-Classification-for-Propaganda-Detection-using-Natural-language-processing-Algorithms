{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %pip show tensorflow\n",
    "# Modeling\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n",
    "\n",
    "# # Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# # Model performance evaluation\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random,math\n",
    "TRAINING_DIR=\"propaganda_dataset_v2\"\n",
    "files=os.listdir(TRAINING_DIR)\n",
    "#since we have just two files we dont need loops\n",
    "traindf= pd.read_csv(os.path.join(TRAINING_DIR,files[0]),sep = '\\t')\n",
    "testdf= pd.read_csv(os.path.join(TRAINING_DIR,files[1]),sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>according to a UN estimate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>causal_oversimplification</td>\n",
       "      <td>the country would not last long without an ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appeal_to_fear_prejudice</td>\n",
       "      <td>gets Earl Warren and Sen. Richard Russel to j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>repetition</td>\n",
       "      <td>infidels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name_calling,labeling</td>\n",
       "      <td>the \"gay lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loaded_language</td>\n",
       "      <td>devastating communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Jacob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flag_waving</td>\n",
       "      <td>Iran’s long rap sheet of aggression against A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doubt</td>\n",
       "      <td>Now, the pope’s reply to my testimony was: “I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label   \n",
       "0             not_propaganda  \\\n",
       "1  causal_oversimplification   \n",
       "2   appeal_to_fear_prejudice   \n",
       "3             not_propaganda   \n",
       "4                 repetition   \n",
       "5      name_calling,labeling   \n",
       "6            loaded_language   \n",
       "7             not_propaganda   \n",
       "8                flag_waving   \n",
       "9                      doubt   \n",
       "\n",
       "                                   tagged_in_context  \n",
       "0                       according to a UN estimate.   \n",
       "1   the country would not last long without an ou...  \n",
       "2   gets Earl Warren and Sen. Richard Russel to j...  \n",
       "3                                               You   \n",
       "4                                          infidels   \n",
       "5                                the \"gay lifestyle   \n",
       "6                           devastating communities   \n",
       "7                                             Jacob   \n",
       "8   Iran’s long rap sheet of aggression against A...  \n",
       "9   Now, the pope’s reply to my testimony was: “I...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text(sentences):\n",
    "    start_sent=sentences.split(\"<BOS>\")\n",
    "    end_sent=start_sent[1].split(\"<EOS>\")\n",
    "    return end_sent[0]\n",
    "\n",
    "testdf[\"tagged_in_context\"]=testdf[\"tagged_in_context\"].map(convert_text)\n",
    "traindf[\"tagged_in_context\"]=traindf[\"tagged_in_context\"].map(convert_text)\n",
    "\n",
    "testdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "not_propaganda               1191\n",
       "exaggeration,minimisation     164\n",
       "causal_oversimplification     158\n",
       "name_calling,labeling         157\n",
       "loaded_language               154\n",
       "appeal_to_fear_prejudice      151\n",
       "flag_waving                   148\n",
       "repetition                    147\n",
       "doubt                         144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf[\"label\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_multiclass(label):\n",
    "    if label==\"flag_waving\":\n",
    "        return 0\n",
    "    elif label==\"appeal_to_fear_prejudice\":\n",
    "        return 1\n",
    "    elif label==\"causal_oversimplification\":\n",
    "        return 2\n",
    "    elif label ==\"doubt\":\n",
    "        return 3\n",
    "    elif label == \"exaggeration,minimisation\":\n",
    "        return 4\n",
    "    elif label == \"loaded_language\":\n",
    "        return 5\n",
    "    elif label == \"name_calling,labeling\":\n",
    "        return 6\n",
    "    elif label == \"repetition\":\n",
    "        return 7\n",
    "     \n",
    "#drop rows with no propanganda\n",
    "\n",
    "testdf=testdf[testdf.label != \"not_propaganda\"]\n",
    "traindf = traindf[traindf.label != \"not_propaganda\"]\n",
    "\n",
    "traindf[\"label\"] = traindf[\"label\"].map(convert_labels_multiclass)\n",
    "testdf[\"label\"] = testdf[\"label\"].map(convert_labels_multiclass)\n",
    "\n",
    "traindf.reset_index(inplace=True)\n",
    "testdf.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>American people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>annihilated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>so-called evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>hateful conduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>point to Iran’s positioning itself for more a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>2403</td>\n",
       "      <td>7</td>\n",
       "      <td>Nazi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2405</td>\n",
       "      <td>4</td>\n",
       "      <td>absolutely no place for anti-Semitism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2406</td>\n",
       "      <td>0</td>\n",
       "      <td>Prosecutors Doing Mueller’s ‘Dirty Work Are A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2407</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither the Democrat leadership nor the Democ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2413</td>\n",
       "      <td>6</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1223 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                  tagged_in_context\n",
       "0         2      0                                   American people \n",
       "1         5      5                                       annihilated \n",
       "2         8      3                                so-called evidence \n",
       "3        10      6                                   hateful conduct \n",
       "4        12      1   point to Iran’s positioning itself for more a...\n",
       "...     ...    ...                                                ...\n",
       "1218   2403      7                                              Nazi \n",
       "1219   2405      4             absolutely no place for anti-Semitism \n",
       "1220   2406      0   Prosecutors Doing Mueller’s ‘Dirty Work Are A...\n",
       "1221   2407      2   Neither the Democrat leadership nor the Democ...\n",
       "1222   2413      6                                           selfish \n",
       "\n",
       "[1223 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "4    164\n",
       "2    158\n",
       "6    157\n",
       "5    154\n",
       "1    151\n",
       "0    148\n",
       "7    147\n",
       "3    144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf[\"label\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_train_data = Dataset.from_pandas(traindf)\n",
    "hg_test_data = Dataset.from_pandas(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_data(data):\n",
    "    return tokenizer(data[\"tagged_in_context\"],\n",
    "                     max_length=140,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f7811c2c394db5a676eeba9887faf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582dea7c041c4c3eae8aa53b04d27204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = hg_train_data.map(tokenize_data)\n",
    "dataset_test = hg_test_data.map(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_transfer_learning_transformer/\",          \n",
    "    logging_dir='./sentiment_transfer_learning_transformer/logs',            \n",
    "    logging_strategy='epoch',\n",
    "    logging_steps=100,    \n",
    "    num_train_epochs=12,              \n",
    "    per_device_train_batch_size=1,  \n",
    "    per_device_eval_batch_size=1,  \n",
    "    learning_rate=5e-6,\n",
    "    seed=42,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=100,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    # probabilities = tf.nn.softmax(logits)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loges\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca827ef59be41dd8d399ff7b005b1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8829, 'learning_rate': 4.583333333333333e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71951d8c96df401fb3906b61160f3471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7379887104034424, 'eval_accuracy': 0.32974910394265233, 'eval_runtime': 13.7787, 'eval_samples_per_second': 20.249, 'eval_steps_per_second': 20.249, 'epoch': 1.0}\n",
      "{'loss': 1.4625, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd16aebabc69477e9ba1a611e277b174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4242676496505737, 'eval_accuracy': 0.4767025089605735, 'eval_runtime': 14.0654, 'eval_samples_per_second': 19.836, 'eval_steps_per_second': 19.836, 'epoch': 2.0}\n",
      "{'loss': 1.0982, 'learning_rate': 3.7500000000000005e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719bf3409a034d238aa2e7a2aad01905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4290001392364502, 'eval_accuracy': 0.4910394265232975, 'eval_runtime': 27.5684, 'eval_samples_per_second': 10.12, 'eval_steps_per_second': 10.12, 'epoch': 3.0}\n",
      "{'train_runtime': 890.1622, 'train_samples_per_second': 16.487, 'train_steps_per_second': 16.487, 'train_loss': 1.4811953827677842, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3669, training_loss=1.4811953827677842, metrics={'train_runtime': 890.1622, 'train_samples_per_second': 16.487, 'train_steps_per_second': 16.487, 'train_loss': 1.4811953827677842, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
